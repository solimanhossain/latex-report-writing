\chapter{Literature Review}

\section{Overview}
This chapter provides an in-depth review of the existing literature on student evaluation systems. It aims to explore various aspects of student evaluation systems, including their purpose, methodologies, effectiveness, and potential challenges. The literature review will serve as a foundation for understanding the current state of research and identifying gaps that need to be addressed in the subsequent chapters. Also the limitations of existing works have been shown in a table for better understanding.


\section{Review of Relevant Works}

The decisions of students to not pursue further education may have been influenced by a lack of direction in the supervision structure and shortcomings of their supervisors, resulting in reduced interaction with students. However, this issue could be effectively addressed by adopting online supervision.

Both students and teachers have worked hard during these terrible times, according to studies (as well as anecdotal data), and they still appreciate a sense of community and belonging, according to anecdotal evidence. Although technology has made it easier for staff and students to communicate with one another, it cannot take the place of a teacher. Both still prefer face-to-face instruction over the virtual or remote methods used to meet the pedagogical needs of students during the pandemic because face-to-face instruction offers intimacy that cannot be replaced by technology and digital tools are only meant to supplement face-to-face learning.\cite{sia2020facing}\\

Crossouard et al. found that changes in higher education courses have affected how teachers and students communicate using computers, and they advocate for supervisors to also adopt online supervision. This involves interpreting vocal and textual communication in the context of online supervision using computers.\cite{crossouard2008developing}

These findings support the study conducted by Hamzah et al. which showed that online supervision is an efficient method for students and supervisors to exchange knowledge, information, and track progress. Online supervision provides flexibility in terms of location and can be conducted under various conditions, as long as there is internet access, allowing both students and supervisors to choose the setting and location that suits them best.\cite{hamzah2017web}\\

Higher education students typically struggle to finish their research project within the allotted time.\cite{costa2018systematic} When it comes to students who are taking DL courses, this issue gets worse. Supervisors are essential to the process of research supervision, regardless of the type of schooling (DL or conventional). It's crucial that supervisors are motivated to watch over the kids. Workload agreements, time constraints, the caliber of the students, and acknowledgment of the supervisors' participation are four elements that have an impact on research supervisors.\cite{askew2016facilitators}\\


The appropriate and efficient use of ICT can create a supportive environment for both thesis students and supervisors. A study found that there was no significant difference between face-to-face and online tutoring using ICT. The use of ICT can be beneficial in providing frequent feedback and fostering a high level of interaction between students and supervisors.\cite{iwasaki2019design} \cite{hansen2015optimizing}\\

The paper titled "Supervision system of English online teaching based on machine learning" presents a comprehensive study on the implementation of an automated supervision system for online English teaching. The article emphasized the necessity for further exploration of the use of automated supervision techniques in high school education, and presented a new approach that combines remote supervision with machine learning algorithms (IRS-MLA).\\ Wen Lu, G. N. et al. explained how IRS-MLA mimics the implementation of supervision methodologies in the online English teaching process, based on actual requirements. The suggested approach entails evaluating the effectiveness of the teaching process by measuring students' performance and learning progress from both the teachers' and their students' perspectives. The paper does not provide a detailed discussion of the limitations of the proposed IRS-MLA system. It would be helpful to identify potential challenges and limitations that may arise in implementing the system in real-world settings. Additionally, the study focused on English language online teaching, and it remains unclear how the proposed approach may apply to other subject areas or disciplines. The paper could also benefit from a discussion of ethical considerations that arise when implementing an automated supervision system in online education, such as issues of privacy and data protection. Finally, while the study reports high levels of accuracy, efficiency, and success ratio compared to existing models, it would be useful to understand the degree of improvement over existing approaches and how the proposed system performs under different conditions and scenarios.\cite{lu2022supervision}\\

The role of Machine learning in Lockdown Exam Management Systems is comprehensively reviewed in the article. Sanaa Kaddoura, Daniela Elena Popescu, and Jude D. and their team effectively illustrate how the COVID-19 pandemic impacted the education sector, leading to the integration of Machine learning in the transition from traditional classroom-based learning to online learning and examination management systems. The article provides a systematic evaluation of 135 studies over the past five years, offering a well-rounded perspective on the various aspects of the exam cycle influenced by Machine learning. The authors categorize the unsupervised or supervised Machine learning algorithms in each process, highlighting their relevance and contribution to exam preparation, conduction, and evaluation. A notable strength of the article is the detailed examination of primary exam aspects such as authentication, scheduling, proctoring, and cheat or fraud detection from a Machine learning perspective. The authors' analysis of main attributes, including the prediction of at-risk students, adaptive learning, and student monitoring, enriches the understanding of Machine learning's role in exam preparation and management.\\
While the article presents a comprehensive overview of the role of Machine learning in Lockdown Exam Management Systems, it is essential to note some limitations. Firstly, the article mainly focuses on the use of Machine learning in the online examination system during the COVID-19 pandemic. The study does not cover the traditional classroom-based examination systems or the long-term impact of Machine learning on the education sector. Secondly, the article mainly discusses the technical aspects of Machine learning, such as authentication, scheduling, proctoring, and cheat or fraud detection, and does not delve into the ethical or social implications of relying heavily on technology for exam management. The study also does not provide insights into the students' perspectives on the use of Machine learning in the exam cycle. Thirdly, the article is limited to the available literature over the last five years. The fast-paced nature of technology may have led to new developments that are not covered in the study. Finally, while the article suggests solutions to the challenges and issues that Machine learning poses to the examination system, the implementation of these solutions may not be feasible or practical in all educational settings.\cite{kaddoura2022systematic}\\

I. Han, Wo. S. Shin et al. investigated the factors influencing the adoption of mobile learning management systems (LMSs) and the effects on students' academic achievement in higher education. The study collected data from 1604 students from an online university in Korea, including demographic backgrounds, psychological data, and external factors. The results showed that age and employment status significantly influenced the adoption of mobile LMSs, and there were potential connections between mobile LMS use and students' gender, age, and psychological characteristics. Furthermore, the use of a mobile LMS had a positive impact on online students' academic achievement. The study's large sample size allowed for generalizability of the results, and the use of logistic regression analysis provided a deeper understanding of the relationships among the variables studied.\\

However, the study has some limitations that should be considered. Firstly, the data was collected from a single online university in Korea, limiting the generalizability of the findings to other contexts. Secondly, the study's use of self-reported data may introduce response bias, as respondents may not always be truthful in their responses.\cite{han2016use} \\

In their study, Y. Fadol, H. Aldamen, S. Saadullah et al. shed light on the effectiveness of different modes of delivery in a management course at a business school in the Middle East. The authors compared the performance and perception of 122 students across three different modes of delivery: traditional, online, and flipped. The study's findings revealed that both online and flipped modes outperformed the traditional mode, with the flipped mode showing the highest performance. Moreover, absenteeism was lower in the flipped mode compared to the traditional mode, indicating higher student engagement in this mode. The study also found that accessing online material improved performance in both online and flipped modes, and students who accessed online material missed fewer classes in the flipped mode. Furthermore, the majority of the students perceived the flipped mode as more beneficial than the traditional mode. The study's strength lies in its comparison of various delivery modes and its use of both quantitative and qualitative data to support the findings. This finding is particularly noteworthy as it suggests that students may prefer a more interactive and engaging learning experience that promotes self-directed learning. The study's implications are significant, as they suggest that educational institutions should consider adopting innovative teaching strategies that are better aligned with students' learning preferences. The findings also indicate that online and flipped modes may be more effective in promoting student engagement and academic performance.\\

% \newpage
However, there are some limitations to this study that need to be addressed. Firstly, the study was conducted at only one institution, and the results may not be generalizable to other institutions or settings. Furthermore, the study did not evaluate the long-term effects of the different modes of delivery on students' academic performance. Nevertheless, the study's findings have significant implications for the development of future educational programs and highlight areas for further research. \cite{fadol2018comparative}\\

The article presents the development and evaluation of a new automated assessment tool for online distributed programming called DSLab. The authors recognize the complexity and difficulty of creating an automated assessment tool and aim to fill this research gap by providing a tool that can enhance students' academic performance in a meaningful distributed learning environment. The study employs a quantitative analysis method to collect and analyze data regarding students' perceptions of using the DSLab tool. The results suggest that the DSLab tool has acceptable utility and efficiency features and provides a valuable experience for students. The article's strength lies in its evaluation of the tool in a real, long-term online educational experience, adding to the validity of the findings. Additionally, the study identifies factors that can enhance the tool's design efficiency by suggesting new functionalities and ideas. However, the study is limited to a single case, and the generalizability of the findings may be constrained.\\

The article by T. Daradoumis et al. focuses on the creation and assessment of DSLab, an automated assessment tool for online distributed programming. While the study provides useful insights into the effectiveness and areas for improvement of the tool, there are some limitations that should be considered. The study only evaluates the tool's effectiveness from the students' perceptions, and the authors did not conduct any objective measurement of the tool's impact on students' academic performance. Thus, it remains unclear whether the use of the DSLab tool actually resulted in improved academic performance for the students. Again the study was conducted in a specific context, and the sample size was relatively small. Thus, it may not be possible to generalize the findings to other contexts or larger populations. Finally, the article does not discuss the potential drawbacks or limitations of using an automated assessment tool in online distributed programming. For example, some students may prefer more traditional forms of assessment or may feel uncomfortable with the technology involved.\cite{daradoumis2019analyzing}\\

The study conducted by I. Noguera, R. Masó et al. examines the effects of incorporating agile strategies into online collaborative learning, and its impact on engagement with learning activities and collaborative processes. Specifically, the research aims to determine if these strategies can enhance planning processes and regulate group work, leading to improved engagement. The study focuses on an undergraduate project-based learning course, and an iterative process of course redesign was conducted during two consecutive semesters. The new design was piloted and evaluated based on the students' and teacher's views and the learning outcomes. The research found that incorporating agile strategies was useful for improving students' online project management and collaboration. However, the study did not find any significant impact on students' satisfaction with the course or the overall learning outcomes. Despite this, the research provides valuable insights into the use of agile strategies for team regulation and project management in online higher education, which can help create a more effective learning environment.\\

One limitation of the study is that it focused on only one undergraduate project-based learning course. As a result, the findings may not be generalizable to other courses or educational levels. Additionally, the study did not measure the long-term impact of incorporating agile strategies on students' learning outcomes or their future collaborative experiences. It would be beneficial to conduct follow-up studies to determine if the strategies introduced in this study have a lasting impact on students' collaborative skills and experiences. Another limitation is that the study relied primarily on self-reported surveys and interviews to collect data. This may lead to biases in responses or limitations in the accuracy of the data collected. The study could have benefitted from using multiple data collection methods, such as observations or assessments, to provide a more comprehensive understanding of the impact of agile strategies on students' collaborative learning experiences. \cite{noguera2018collaborative}\\

R. Dad, S. N. Pasha, M. Sallauddin et al. implies that only a limited number of tools possess the ability to assess essays based on their content, and a smaller subset still are utilizing natural language processing techniques. Natural language processing is a powerful technique that can analyze and understand human language. The use of natural language processing in automated assessment tools could potentially revolutionize the way we evaluate essays. This study highlights the importance of assessment in the education system and the increasing interest in using automatic tools to aid in the assessment process. While there have been significant advancements in automatic assessment tools for objective-type questions, there is still room for improvement in the assessment of essays. The integration of natural language processing methods could potentially solve this problem and provide more accurate and reliable assessments of student essays.\\

One of the limitations of automated essay assessment tools is their inability to fully capture the nuances and creativity of human language. While natural language processing techniques have improved significantly in recent years, it is still difficult for automated tools to fully understand and evaluate the meaning and context of a piece of writing. Additionally, automated assessment tools may not be able to recognize more subjective aspects of writing, such as the emotional impact of a piece or the tone and voice of the author. These qualities may be important in certain types of writing, such as creative writing or personal narratives. Another limitation is that automated assessment tools may not be able to provide the same level of feedback and guidance that a human instructor can provide. While these tools can provide a score or grade, they may not be able to offer the same level of personalized feedback and constructive criticism that a human instructor can provide to help students improve their writing skills. \cite{dadi2020overview}\\

A.Shehab, M. Faroun, M. Rashad presents an informative review on the problems associated with manual grading and the need for auto-grading systems in the educational community. It highlights the advantages of auto-grading systems such as cost, time, and effort-saving compared to manual grading. The study also focuses on the specific challenge of developing auto-grading systems for Arabic languages due to complexities in morphology, semantics, and syntax. The research conducted a comparison of different algorithms used in automatic grading systems for Arabic languages using string and corpus algorithms separately. The use of multiple similarity measures and the introduction of an Arabic dataset containing 210 students’ answers make the study more comprehensive. The results obtained indicate that automatic grading systems can provide an effective solution for article grading systems.\\

The article could have included a discussion on the limitations of auto-grading systems. While auto-grading systems have many advantages, they are not without limitations. For example, they may not be suitable for assessing certain types of assignments that require subjective evaluation or critical thinking. Also, auto-grading systems may not be able to detect plagiarism, which can be a significant issue in the educational context. Furthermore, the study only focused on comparing different algorithms for automatic grading systems for Arabic language articles. It did not discuss the applicability of these algorithms in other contexts or for other types of assignments. Therefore, the generalizability of the results to other languages or assignment types is unclear. \cite{shehab2018automatic}

The importance of high-quality online course websites in facilitating effective learning experiences for students cannot be overstated. In this paper, S. Chakkrit et al. present an extended version of an evaluation framework for online courses and Learning Management Systems (LMS) that aims to address the shortcomings identified through its application in various e-learning courses. One of the key enhancements of the new version of the evaluation framework is the inclusion of a web-based questionnaire in both Thai and English languages. This addition makes it more accessible and user-friendly for a broader range of users, facilitating easier evaluation of online courses and LMS. Additionally, the authors have incorporated an authorization process, ensuring that only authorized individuals can access and complete the questionnaire, thereby enhancing the integrity of the evaluation process. Another notable feature of the extended framework is the introduction of a role-based evaluation process. This acknowledges the diverse perspectives and needs of different stakeholders involved in the evaluation, such as instructors, students, and administrators. By considering the unique requirements and expectations of each role, the framework enables a more comprehensive assessment of the online courses and LMS from multiple viewpoints. 

The authors state that the extended framework will be incorporated into O-DEST; they do not provide information on the practical implementation challenges that may arise during the integration process. Implementing an evaluation framework in real-world settings often involves various logistical, technical, and organizational hurdles that may affect its successful adoption and usage. \cite{snae2008web}


\section{Limitations of the Existing Systems}
In-depth comments or nuanced responses from students may not be possible in online student evaluation systems. The chance for instructors to follow up with students or explain input may not be offered, which could restrict the usefulness of the feedback given and leave open the possibility of failing to address any concerns or queries from the students. Additionally, the majority of current systems and models do not come with auto-marking systems.
\begin{table}[H]
\centering
\caption{A tabular format of various approaches along with limitations\\}

\begin{tabular}{ p{.5cm} p{5.5cm} p{7.5cm} } 
\hline
Ref. & Approaches & Limitations \\
\hline
[4] & Quantitative research on questionnaire survey  & Only did the research but was not able to build the system  \\ 
\hline
[9] & Proposed an automated IRS-MLA supervision system & The system was applied only on English online teaching and there was no guidelines on how to apply it on other topics\\ 
\hline
[10] & Categorized the system by Machine Learning Algorithms for exam management & The implementation system can not provide the feasibility in all types of educational settings \\ 
\hline
[15] & Assessed essays by NLP process tools & The tools was not able to provide any scores \\ 
\hline
\cite{shehab2018automatic} & Established an auto-grading system & The system was built only on Arabic Language which is not acceptable for all other educational institutes.\\
\hline
\end{tabular}
\label{table2.1}
\end{table}
